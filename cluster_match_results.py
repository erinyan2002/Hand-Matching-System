import os
import glob
import cv2
import torch
import numpy as np
from itertools import combinations
from collections import defaultdict
from sklearn.cluster import DBSCAN
from models.matching import Matching
from models.utils import frame2tensor, make_matching_plot_fast, error_colormap

# ======= ì„¤ì • =======
IMAGE_FOLDER = 'assets/hand3'
RESULT_FOLDER = 'results'
MATCH_THRESHOLD = 100
DEVICE = 'cpu'
RESIZE_SHAPE = (640, 480)
CLUSTER_EPS = 0.05  # ê±°ë¦¬ ê¸°ì¤€ê°’
CLUSTER_MIN_SAMPLES = 2

# ======= ì´ˆê¸°í™” =======
os.makedirs(RESULT_FOLDER, exist_ok=True)
config = {
    'superpoint': {
        'nms_radius': 4,
        'keypoint_threshold': 0.005,
        'max_keypoints': 1024
    },
    'superglue': {
        'weights': 'indoor',
        'sinkhorn_iterations': 20,
        'match_threshold': 0.2
    }
}
matching = Matching(config).eval().to(DEVICE)

def load_image_gray(path):
    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    img = cv2.resize(img, RESIZE_SHAPE)
    return img

# ======= ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸° =======
image_paths = sorted(glob.glob(os.path.join(IMAGE_FOLDER, '*.*')))
image_names = [os.path.basename(p) for p in image_paths]
num_images = len(image_paths)
print(f"ğŸ” ì²˜ë¦¬ ëŒ€ìƒ ì´ë¯¸ì§€ ìˆ˜: {num_images}ì¥")

# ======= ê±°ë¦¬ í–‰ë ¬ ë° ë§¤ì¹­ ë¡œê·¸ ì´ˆê¸°í™” =======
distance_matrix = np.ones((num_images, num_images)) * np.inf
np.fill_diagonal(distance_matrix, 0)

# ======= ì „ì²´ ì¡°í•© ë¹„êµ =======
for (idx_a, path_a), (idx_b, path_b) in combinations(enumerate(image_paths), 2):
    name_a = image_names[idx_a]
    name_b = image_names[idx_b]

    img0 = load_image_gray(path_a)
    img1 = load_image_gray(path_b)
    inp0 = frame2tensor(img0, DEVICE)
    inp1 = frame2tensor(img1, DEVICE)

    with torch.no_grad():
        pred = matching({'image0': inp0, 'image1': inp1})

    kpts0 = pred['keypoints0'][0].cpu().numpy()
    kpts1 = pred['keypoints1'][0].cpu().numpy()
    matches = pred['matches0'][0].cpu().numpy()
    valid = matches > -1
    mkpts0 = kpts0[valid]
    mkpts1 = kpts1[matches[valid]]
    scores = pred['matching_scores0'][0].detach().cpu().numpy()[valid]
    color = error_colormap(scores)[:, :3]

    match_count = np.sum(valid)
    is_same = match_count >= MATCH_THRESHOLD
    label = "SAME" if is_same else "DIFF"
    print(f"{name_a} â†” {name_b} : {match_count}ì  â†’ {label}")

    # ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
    result_path = os.path.join(RESULT_FOLDER, f"{name_a}_vs_{name_b}_{label}_{match_count}.png")
    make_matching_plot_fast(
        img0, img1, kpts0, kpts1, mkpts0, mkpts1, color,
        text=[f"{name_a} vs {name_b}", f"{match_count} matches", f"{label}"],
        path=result_path,
        show_keypoints=False
    )

    # ìœ ì‚¬ë„ë¥¼ ê±°ë¦¬ë¡œ ë³€í™˜
    dist = 1.0 / (match_count + 1e-5)
    distance_matrix[idx_a, idx_b] = dist
    distance_matrix[idx_b, idx_a] = dist

# ======= í´ëŸ¬ìŠ¤í„°ë§ =======
clustering = DBSCAN(eps=CLUSTER_EPS, min_samples=CLUSTER_MIN_SAMPLES, metric='precomputed')
labels = clustering.fit_predict(distance_matrix)

# ======= í´ëŸ¬ìŠ¤í„° ì¶œë ¥ =======
cluster_map = defaultdict(list)
for idx, label in enumerate(labels):
    cluster_map[label].append(image_names[idx])

print("\nâœ… í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼:")
for label, images in cluster_map.items():
    label_text = f"í´ëŸ¬ìŠ¤í„° {label}" if label != -1 else "ë…¸ì´ì¦ˆ"
    print(f"\nğŸŸ¢ {label_text}:")
    for img in images:
        print(f"  - {img}")

print("\nâœ… ì²˜ë¦¬ ì™„ë£Œ! ë§¤ì¹­ ê²°ê³¼ ë° í´ëŸ¬ìŠ¤í„° ì •ë³´ë¥¼ ì¶œë ¥í–ˆìŠµë‹ˆë‹¤.")
